=====================================
PyPy Coding Style
=====================================

.. contents::
.. sectnum::

Restricted Python
==================

We are writing a Python interpreter in Python, using Python's well known ability 
to step behind the algorithmic problems as language. At first glance, one might 
think this achieves nothing but a better understanding how the interpreter works. 
This alone would make it worth doing, but we have much larger goals. 


CPython vs. PyPy
-------------------

Compared to the CPython implementation, Python takes the role of the C
Code. We rewrite the CPython interpreter in Python itself.  We could
also aim at writing a more flexible interpreter at C level but but we
want to use Python to give an alternative description of the interpreter.

The clear advantage is that such a description is shorter and simpler to 
read, and many implementation details vanish. The drawback of this approach is 
that this interpreter will be unbearably slow as long as it is run on top
of CPython.

To get to a useful interpreter again, we need to translate our
high-level description of Python to a lower level one.  One rather
straight-forward way is to do a whole program analysis of the PyPy
interpreter and create a C source, again. There are many other ways, 
but let's stick with this somewhat canonical approach.  

our runtime interpreter is "restricted python" 
----------------------------------------------

In order to make a C code generator feasible we restrict ourselves to a
subset of the Python language, and we adhere to some rules which make
translation to lower level langauges more obvious. 

Unlike source-to-source translations (like e.g. Starkiller_) we start
translation from live python code objects which constitute our Python
interpreter.   When doing its work of interpreting bytecode our Python
implementation must behave in a static way often referenced as 
"RPythonic". 

.. _Starkiller: http://www.python.org/pycon/dc2004/papers/1/paper.pdf

However, when the PyPy interpreter is started as a Python program, it
can use all of the Python language until it reaches interpretation
runtime. That is, during initialisation our program is free to use the
full dynamism of Python, including dynamic code generation. 

An example can be found in the current implementation which is quite
elegant: For the definition of all the opcodes of the Python
interpreter, the module ``dis`` is imported and used to initialize our
bytecode interpreter.  (See ``__initclass_`` in `pyopcode.py`_).  This
saves us from adding extra modules to PyPy. The import code is run at
startup time, and we are allowed to use the CPython builtin import
function.

After the startup code is finished, all resulting objects, functions,
code blocks etc. must adhere to certain runtime restrictions which we
describe further below.  Here is some background for why this is so:
during translation, a whole program analysis ("type inference") is
performed, which makes use of the restrictions defined in RPython. This
enables the code generator to emit efficient machine level replacements
for pure integer objects, for instance.   

.. _`pyopcode.py`: http://codespeak.net/svn/pypy/dist/pypy/interpreter/pyopcode.py 

RPython Definition, not
-----------------------

The list and exact details of the "RPython" restrictions are a somewhat 
evolving topic.  In particular, we have no formal language definition
as we find it more practical to discuss and evolve the set of 
restrictions while working on the whole program analysis.  If you
have any questions about the restrictions below then please feel
free to mail us at pypy-dev at codespeak net. 

.. _`wrapped object`: objspace.html#wrapping-rules

Object restrictions
-------------------------

We are using

**variables**
  
  the same variable in the same context can receive values of different types, 
  at a possible overhead cost. For example, a variable that can contain a 
  `wrapped object`_ or None is efficiently implemented as a PyObject* pointer that 
  can be NULL, but a variable that can contain either an integer or a float must 
  be implemented as a union with a type tag in C.

**constants**
  
  all module globals are considered constants.

**integer, float, string, boolean**
  
  avoid string methods and complex operations like slicing with a step

**tuples**
  
  no variable-length tuples; use them to store or return pairs or n-tuples of 
  values

**lists**
  
  lists are used as an allocated array; list.append() does naive resizing, so as 
  far as possible use list comprehensions (see below).  list.extend() or the +=
  operator are allowed and efficient.  Unless there is really a use case for it,
  repetition is limited to initialization purposes: '[single_value] * length'.

**dicts**
  
  dicts with string keys only (preferrably the kind of strings that are usually
  interned in CPython, i.e. short strings that look like identifiers).  The
  implementation could safely decide that all dict keys should be interned.

**control structures**
  
  all allowed

**list comprehensions**
  
  may be used to create allocated, initialized array. the array size must be 
  computable in advance, which implies that we don't allow an if clause.

**functions**

+ statically called functions may use defaults and a variable number of 
  arguments (which may be passed as a list instead of a tuple, so write code that 
  does not depend on it being a tuple).

+ dynamic dispatch enforces use of very simple signatures, equal for all 
  functions to be called in that context. At the moment, this occurs in the opcode 
  dispatch, only.

**builtin functions**

  A few builtin functions will be used, while this set is not defined 
  completely, yet. Some builtin functions are special forms:

**range**
  
  does not create an array. It is only allowed in for loops. The step argument 
  must be a constant.

**len**

+ may be used with basic types that have a length. But len is a special form 
  that is recognized by the compiler.

+ If a certain structure is never touched by len, the compiler might save the 
  length field from the underlying structure.

``int, float, ord, chr``... are available as simple conversion functions.

``int, float, str``... have a special meaning as a type inside of isinstance only.

**classes**

+ methods and other class attributes do not change after startup
+ inheritance is supported
+ classes are first-class objects too

**exceptions**

+ fully supported
+ see below for restrictions on exceptions raised by built-in operations

**objects**

  wrapped objects are borrowed from the object space. Just like in CPython, code 
  that needs e.g. a dictionary can use a wrapped dict and the object space 
  operations on it.

This layout makes the number of types to take care about quite limited.


Integer Types
-------------------------

While implementing the integer type, we stumbled over the problem, that 
integers are quite in flux in CPython right now. Starting on Python 2.2,
integers mutate into longs on overflow.  However, shifting to the left truncates
up to 2.3 but extends to longs as well in 2.4.  By contrast, we need a way to
perform wrap-around machine-sized arithmetic by default, while still being
able to check for overflow when we need it explicitely.  Moreover, we need a
consistent behavior before and after translation.

We use normal integers for signed arithmetic.  It means that before
translation we get longs in case of overflow, and after translation we get a
silent wrap-around.  Whenever we need more control, we use the following
helpers:

**ovfcheck()**

  This special function should only be used with a single arithmetic operation
  as its argument, e.g. ``z = ovfcheck(x+y)``.  Its intended meaning is to
  perform the given operation in overflow-checking mode.
  
  At run-time, in Python, the ovfcheck() function itself checks the result
  and raises OverflowError if it is a ``long``.  But the code generators use
  ovfcheck() as a hint: they replace the whole ``ovfcheck(x+y)`` expression
  with a single overflow-checking addition in C.

**ovfcheck_lshift()**

  ovfcheck_lshift(x, y) is a workaround for ovfcheck(x<<y), because the
  latter doesn't quite work in Python prior to 2.4, where the expression
  ``x<<y`` will never return a long if the input arguments are ints.  There is
  a specific function ovfcheck_lshift() to use instead of some convoluted
  expression like ``x*2**y`` so that code generators can still recognize it as
  a single simple operation.

**intmask()**

  This function is used for wrap-around arithmetic.  It returns the lower bits
  of its argument, masking away anything that doesn't fit in a C "signed long int".
  Its purpose is, in Python, to convert from a Python ``long`` that resulted from a 
  previous operation back to a Python ``int``.  The code generators ignore
  intmask() entierely, as they are doing wrap-around signed arithmetic all the time
  by default anyway.  (We have no equivalent of the "int" versus "long int"
  distinction of C at the moment and assume "long ints" everywhere.)

**r_uint**

  In a few cases (e.g. hash table manipulation), we need machine-sized unsigned
  arithmetic.  For these cases there is the r_uint class, which is a pure
  Python implementation of word-sized unsigned integers that silently wrap
  around.  The purpose of this class (as opposed to helper functions as above)
  is consistent typing: both Python and the annotator will propagate r_uint
  instances in the program and interpret all the operations between them as
  unsigned.  Instances of r_uint are special-cased by the code generators to
  use the appropriate low-level type and operations.
  Mixing of (signed) integers and r_uint in operations produces r_uint that
  means unsigned results.  To convert back from r_uint to signed integers, use
  intmask().


Exception rules
---------------------

Exceptions are by default not generated for simple cases.::

    #!/usr/bin/python

        lst = [1,2,3,4,5]
        item = lst[i]    # this code is not checked for out-of-bound access

        try:
            item = lst[i]
        except IndexError:
            # complain

Code with no exception handlers does not raise exceptions (after it has been
translated, that is.  When you run it on top of CPython, it always may raise
exceptions, of course). By supplying an exception handler, you ask for error
checking. Without, you assure the system that the operation cannot fail.
This rule does not apply to *function calls*: any called function is
assumed to be allowed to raise any exception.

For example::

    x = 5.1
    x = x + 1.2       # not checked for float overflow
    try:
        x = x + 1.2
    except OverflowError:
        # float result too big

But::

    z = some_function(x, y)    # can raise any exception
    try:
        z = some_other_function(x, y)
    except IndexError:
        # only catches explicitely-raised IndexErrors in some_other_function()
        # other exceptions can be raised, too, and will not be caught here.

The ovfcheck() function described above follows the same rule: in case of
overflow, it explicitely raise OverflowError, which can be caught anywhere.

Exceptions explicitly raised or re-raised will always be generated.

PyPy is debuggable on top of CPython 
------------------------------------ 

PyPy has the advantage that it is runnable on standard
CPython.  That means, we can run all of PyPy with all exception
handling enabled, so we might catch cases where we failed to
adhere to our implicit assertions.

Naming and development conventions 
================================== 

Naming
------

- directories/modules/namespaces are always **lowercase**

- classes are **CamelCase**

- never use plural names in directory and file names

- ``__init__.py`` is always empty except for ``pypy/objspace/*``
  and ``pypy/module/*``. 

- functions/methods are lowercase and ``'_'-separated`` (if
  you need to separate at all)

- not more than 4 directory nesting levels

- it's appreciated if you manage to name files in a directory
  so that tab-completion on the shell level is as easy as possible. 

- objectspace classes are always spelled "ObjSpace". e.g.

  - StdObjSpace
  - FlowObjSpace

- at interpreter level and in ObjSpace all boxed values
  have a leading ``w_`` to indicate "wrapped values".  This
  includes w_self.  Don't use ``w_`` in application level
  python only code.


Committing
----------

- it's nice to write good log messages because several people
  are reading the diffs. 

- if you add (text/py) files to the repository then please run
  pypy/tool/fixeol in that directory.  This will make sure 
  that the property 'svn:eol-style' is set to native which 
  allows checkin/checkout in native line-ending format.


Test Design
=============

Our tests are based on the new `py.test`_ tool which lets you write
unittests without boilerplate.  All tests of modules
in a directory usually reside in a subdirectory **test**.  There are
basically two types of unit tests:

- **Interpreter Level tests**. They run at the same level as PyPy's
  interpreter.

- **Application Level tests**. They run at application level which means
  that they look like straight python code but they are interpreted by PyPy.

Both types of tests need an objectspace they can run with (the interpreter
dispatches operations on objects to an objectspace).  If you run a test you
can usually give the '-o' switch to select an object space.  E.g. '-o thunk' 
will select the thunk object space. The default is the "Standard Object Space" 
which aims to implement unmodified Python semantics. 

.. _`py.test`: http://codespeak.net/py/current/doc/test.html 

Interpreter level tests 
----------------------- 

You can write test functions and methods like this:: 

    def test_something(space): 
        # use space ... 
        
    class TestSomething: 
        def test_some(self): 
            # use 'self.space' here 

Note that the prefix `test` for test functions and `Test` for test
classes is mandatory.  In both cases you can import Python modules at
module global level and use plain 'assert' statements thanks to the
usage of the `py.test`_ tool.  

Application Level tests 
----------------------- 

For testing the conformance and well-behavedness of PyPy it
is often sufficient to write "normal" application-level 
Python code that doesn't need to be aware of any particular
coding style or restrictions.  If we have a choice we often
use application level tests which usually look like this: 

    def app_test_something():
        # application level test code 

    class AppTestSomething: 
        def test_this(self): 
            # application level test code 

These application level test functions will run on top
of PyPy, i.e. they have no access to interpreter details. 
You cannot use imported modules from global level because
they are imported at intepreter-level while you test code
runs at application level. If you need to use modules
you have to import them within the test function. 

Command line tool test_all
--------------------------

You can run almost all of PyPy's tests by invoking::

  python test_all.py

which is a synonym for the general `py.test`_ utility. 
For switches to modify test execution invoke "python test_all.py -h".

Test conventions
----------------

- adding features requires adding appropriate tests.  (It often even
  makes sense to first write the tests so that you are sure that they
  actually can fail.) 

- All over the pypy source code there are test/ directories 
  which contain unittests.  Such scripts can usually be executed
  directly or are collectively run by pypy/test_all.py 

- each test directory needs a copy of pypy/tool/autopath.py which
  upon import will make sure that sys.path contains the directory
  where 'pypy' is in. 

PyPy Documentation
==================

Adding documentation 
-------------------- 

Please add new or updated documentation by checking it in to the appropriate 
directory in subversion, usually under 
http://codespeak.net/svn/pypy/dist/pypy/documentation 

+ Remember to run ``svn up`` **before** doing any commit.
+ All filenames should be lowercase, and documentation should be .txt files.
+ Mark-up the documentation with reST so it can generate a pretty html version.
+ On the server side a commit on the doc-subtree will immediately update the webpage. 

*Note*  If you don't markup the textfile, it'll still be checked in, but when docutils 
runs the parser, it'll look ugly on the website. So run docutils yourself before you commit it. 

Some reST basics:
-----------------

There should be a title on your page. Do it like this::

 Here is my Title
 ==================

 Here is a section title
 -------------------------

Make sure you have a blank line after your = or - lines or it will give you an error.
For marking a block of code so it'll look right, you can::

 Put a line of text ending with ::
  indent your code at least one space
  my code
    more code
      even more code
  still more code

End of the "block" occurs whenever you unindent back to the same level as the
text with the ``::`` at the end.

Using an underscore after a word like ``this_`` will make reST think you want a hyperlink.
To avoid that (especially with things like ``wrap_``), you can use the `` back quote ``
to mark it as plain text.

You can get more info on reST markup at http://docutils.sourceforge.net/docs/rst/quickref.html


Automatically testing documentation changes
------------------------------------------- 

.. _`docutils home page`: 
.. _`docutils`: http://docutils.sourceforge.net/ 

We automatically check referential integrity and ReST-conformance.  In order to 
run the tests you need docutils_ installed.  Then go to the local checkout 
of the documentation directory and run the tests:: 

    cd .../pypy/documentation 
    python ../test_all.py 

If you see no failures chances are high that your modifications at least 
don't produce ReST-errors or wron local references.  A side effect of running
the tests is that you have `.html` files in the documentation directory 
which you can point your browser to! 

Additionally, if you also want to check for remote references inside 
the documentation issue:: 

    python ../test_all.py --checkremote 

which will check that remote URLs are reachable.  

