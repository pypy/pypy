===================================================================
Alternative object implementations in the PyPy standard interpreter
===================================================================

.. contents:: Contents

Introduction
============

One of the advantages of the PyPy standard interpreter (compared to CPython) is
that we can provide several implementations of the same object (e.g. for lists
and strings) without the user noticing any difference. This makes it easy to
provide a specialized implementation of a type that is optimized for a certain
situation without disturbing the implementation for the regular case.

We have implemented several such optimizations. Most of them are not enabled by
default. Also, it is not clear for all these optimizations whether they are
worth it in practice, for a real-world application (they sure make some
microbenchmarks a lot faster and use less memory, which is not saying too much).
If you have any observation in that direction, please let us know! By the way:
alternative object implementations are a great way to get into PyPy development
since you have to know only a rather small part of PyPy to do them. And they are
fun too!

String optimizations
====================

string-join objects
-------------------

String-join objects are a different implementation of the Python ``str`` type,
They represent the lazy addition of several strings without actually performing
the addition (which involves copying etc.). When the actual value of the string
join object is needed, the addition is performed. This makes it possible to
perform repeated string additions in a loop without using the
``"".join(list_of_strings)`` pattern.

You can this feature enable with the :config:`objspace.std.withstrjoin` option.

string-slice objects
--------------------

String-slice objects are another implementation of the Python ``str`` type.
They represent the lazy slicing of a string without actually performing the
slicing (which would involve copying). This is only done for slices of step
one. When the actual value of the string slice object is needed, the slicing
is done (although a lot of string methods don't make this necessary). This
makes string slicing a very efficient operation. It also saves memory in some
cases but can also lead to memory leaks, since the string slice retains a
reference to the original string (to make this a bit less likely, we don't
use lazy slicing when the slice would be much shorter than the original
string.  There is also a minimum number of characters below which being lazy
is not saving any time over making the copy).

You can enable this feature with the :config:`objspace.std.withstrslice` option.

Ropes
-----

Ropes are a general flexible string implementation, following the paper `"Ropes:
An alternative to Strings."`_ by Boehm, Atkinson and Plass. Strings are
represented as balanced concatenation trees, which makes slicing and
concatenation of huge strings efficient.

Using ropes is usually not a huge benefit for normal Python programs that use
the typical pattern of appending substrings to a list and doing a
``"".join(l)`` at the end. If ropes are used, there is no need to do that.
A somewhat silly example of things you can do with them is this::

    $ bin/py.py --objspace-std-withrope
    faking <type 'module'>
    PyPy 0.99.0 in StdObjSpace on top of Python 2.4.4c1 (startuptime: 17.24 secs)
    >>>> import sys
    >>>> sys.maxint
    2147483647
    >>>> s = "a" * sys.maxint
    >>>> s[10:20]
    'aaaaaaaaaa'


You can enable this feature with the :config:`objspace.std.withrope` option.

.. _`"Ropes: An alternative to Strings."`: http://www.cs.ubc.ca/local/reading/proceedings/spe91-95/spe/vol25/issue12/spe986.pdf

Integer optimizations
=====================

caching small integers
----------------------

Similar to CPython, it is possible to enable caching of small integer objects to
not have to allocate all the time when doing simple arithmetic. Every time a new
integer object is created it is checked whether the integer is small enough to
be retrieved from the cache.

You can enable this feature with the :config:`objspace.std.withsmallint` option.

integers as tagged pointers
---------------------------

An even more aggressive way to save memory when using integers is "small int"
integer implementation. It is another integer implementation used for integers
that only needs 31 bits (or 63 bits on a 64 bit machine). These integers
are represented as tagged pointers by setting their lowest bits to distinguish
them from normal pointers. This completely avoids the boxing step, saving
time and memory.


Dictionary optimizations
========================

multi-dicts
-----------

Multi-dicts are a special implementation of dictionaries.  It became clear that
it is very useful to *change* the internal representation of an object during
its lifetime.  Multi-dicts are a general way to do that for dictionaries: they
provide generic support for the switching of internal representations for
dicts.

If you just enable multi-dicts, special representations for empty dictionaries,
for string-keyed dictionaries. In addition there are more specialized dictionary
implementations for various purposes (see below).

You can enable this feature with the :config:`objspace.std.withmultidict`
option.

.. XXX chunked dicts, small dicts

sharing dicts
-------------

Sharing dictionaries are a special representation used together with multidicts.
This dict representation is used only for instance dictionaries and tries to
make instance dictionaries use less memory (in fact, in the ideal case the
memory behaviour should be mostly like that of using __slots__).

The idea is the following: Most instances of the same class have very similar
attributes, and are even adding these keys to the dictionary in the same order
while ``__init__()`` is being executed. That means that all the dictionaries of
these instances look very similar: they have the same set of keys with different
values per instance. What sharing dicts do is store these common keys into a
common structure object and thus save the space in the individual instance
dicts:
the representation of the instance dict contains only a list of values.

You can enable this feature with the :config:`objspace.std.withsharingdict`
option.

builtin-shadowing
-----------------

Usually the calling of builtins in Python requires two dictionary lookups: first
to see whether the current global dictionary contains an object with the same
name, then a lookup in the ``__builtin__`` dictionary. This is somehow
circumvented by storing an often used builtin into a local variable to get
the fast local lookup (which is a rather strange and ugly hack).

The same problem is solved in a different way by "wary" dictionaries. They are
another dictionary representation used together with multidicts. This
representation is used only for module dictionaries. The representation checks on
every setitem whether the key that is used is the name of a builtin. If this is
the case, the dictionary is marked as shadowing that particular builtin.

To identify calls to builtins easily, a new bytecode (``CALL_LIKELY_BUILTIN``)
is introduced. Whenever it is executed, the globals dictionary is checked
to see whether it masks the builtin (which is possible without a dictionary
lookup).  Then the ``__builtin__`` dict is checked in the same way,
to see whether somebody replaced the real builtin with something else. In the
common case, the program didn't do any of these; the proper builtin can then
be called without using any dictionary lookup at all.

You can enable this feature with the
:config:`objspace.opcodes.CALL_LIKELY_BUILTIN` option.


List optimizations
==================

range-lists
-----------

Range-lists solve the same problem that the ``xrange`` builtin solves poorly:
the problem that ``range`` allocates memory even if the resulting list is only
ever used for iterating over it. Range lists are a different implementation for
lists. They are created only as a result of a call to ``range``. As long as the
resulting list is used without being mutated, the list stores only the start, stop
and step of the range. Only when somebody mutates the list the actual list is
created. This gives the memory and speed behaviour of ``xrange`` and the generality
of use of ``range``, and makes ``xrange`` essentially useless.

You can enable this feature with the :config:`objspace.std.withrangelist`
option.

multi-lists
-----------

As with dictionaries it became clear that it is generally useful to allow lists
to change their internal representation over their lifetime. Therefore
multi-lists were implemented, mostly equivalently to multi-dicts. The special
representations you get by default are for empty lists, for lists containing
only strings and ranges again (the reason why range lists and multilists both
implement the same optimization is that range lists came earlier and that
multi-lists are not tested that much so far).

You can enable this feature with the :config:`objspace.std.withmultilist`
option.


fast list slicing
------------------

A rather experimental special list representation used with multilists is the
slice list (the original idea is from `Neal Norwitz on pypy-dev`_). The
observation is that slices are often created for iterating over them, so it
seems wasteful to create a full copy of that portion of the list. Instead the
list slice is only created lazily, that is when either the original list or
the sliced list is mutated.

You can enable this feature with the :config:`objspace.std.withfastslice`
option.

.. _`Neal Norwitz on pypy-dev`: http://codespeak.net/pipermail/pypy-dev/2005q4/002538.html


User class optimizations
========================

Shadow tracking
---------------

Shadow tracking is a general optimization that speeds up method calls for user
classes (that don't have special meta-class). For this a special dict
representation is used together with multidicts. This dict representation is
used only for instance dictionaries. The instance dictionary tracks whether an
instance attribute shadows an attribute of its class. This makes method calls
slightly faster in the following way: When calling a method the first thing that
is checked is the class dictionary to find descriptors. Normally, when a method
is found, the instance dictionary is then checked for instance attributes
shadowing the class attribute. If we know that there is no shadowing (since
instance dict tells us that) we can save this lookup on the instance dictionary.

You can enable this feature with the :config:`objspace.std.withshadowtracking`
option.


Method caching
--------------

Shadow tracking is also an important building block for the method caching
optimization. A method cache is introduced where the result of a method lookup
is stored (which involves potentially many lookups in the base classes of a
class). Entries in the method cache are stored using a hash computed from
the name being looked up, the call site (i.e. the bytecode object and
the current program counter), and a special "version" of the type where the
lookup happens (this version is incremented every time the type or one of its
base classes is changed). On subsequent lookups the cached version can be used,
as long as the instance did not shadow any of its classes attributes.

You can enable this feature with the :config:`objspace.std.withmethodcache`
option.

.. CALL_METHOD?
